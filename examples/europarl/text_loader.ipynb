{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from frostings.loader import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_samples(samples):\n",
    "    # remove input sentences that are too short or too long\n",
    "    samples = [((x, l1), (t, l2)) for (x, l1), (t, l2) in samples if len(x) > 1 and len(x) <= 400]\n",
    "\n",
    "    # remove target sentences that are too short or too long\n",
    "    samples = [((x, l1), (t, l2)) for (x, l1), (t, l2) in samples if len(t) > 1 and len(t) <= 450]\n",
    "\n",
    "    return samples\n",
    "\n",
    "# prepare a dictionary for mapping characters to integer tokens\n",
    "\n",
    "def get_dictionary_char(lang = 'en'):\n",
    "    with open('./data/alphabet.' + lang, 'r') as f:\n",
    "        alphabet_raw = f.read().replace('\\r\\n', '\\n').replace('\\r', '\\n') # removing microsoft formatting\n",
    "        alphabet = list(set(alphabet_raw)) # removing duplicate entries\n",
    "    return {character: idx for idx, character in enumerate(alphabet)}\n",
    "\n",
    "def char_encoding(sentence, alphadict):\n",
    "    # gets the encoding e.g. a = 180\n",
    "    encode = lambda c: alphadict[c]\n",
    "    # concatenating each char in the string to np.array.shape(len(sentence), len(alphadict))\n",
    "    encoding = [encode(c) for c in sentence]\n",
    "    return np.array(encoding)\n",
    "\n",
    "def spaces(sentence):\n",
    "    spaces = [idx-1 for idx, c in enumerate(sentence) if c == \" \"]\n",
    "    spaces.append(len(sentence)-1)\n",
    "    return np.array(spaces)\n",
    "\n",
    "def char_length(in_string):\n",
    "    return len(in_string)\n",
    "\n",
    "class TextLoadMethod(LoadMethod):\n",
    "\n",
    "    def _load_data(self):\n",
    "        with open(\"data/train/europarl-v7.fr-en.en\", \"r\") as f:\n",
    "            self.train_X = f.read().split(\"\\n\")\n",
    "            language = [\"en\" for _ in range(len(self.train_X))]\n",
    "            self.train_X = zip(self.train_X, language)\n",
    "        with open(\"data/train/europarl-v7.fr-en.fr\", \"r\") as f:\n",
    "            self.train_t = f.read().split(\"\\n\")\n",
    "            language = [\"fr\" for _ in range(len(self.train_t))]\n",
    "            self.train_t = zip(self.train_t, language)\n",
    "        self.samples = zip(self.train_X, self.train_t)\n",
    "\n",
    "    def _preprocess_data(self):\n",
    "        char_dict = dict()\n",
    "        char_dict['en'] = get_dictionary_char()\n",
    "        char_dict['fr'] = get_dictionary_char('fr')\n",
    "        \n",
    "        if self.samples == None:\n",
    "            self._load_data()\n",
    "        self.samples = sorted(self.samples, key=lambda (X, t): len(X)*10000 + len(t))\n",
    "        # remove samples not of interest\n",
    "        self.samples = remove_samples(self.samples)\n",
    "        for sample_idx, sample in enumerate(self.samples):\n",
    "            my_s = []\n",
    "            # samples should be tuple((train_X, \"en\") (train_t, \"fr\"))\n",
    "            for elem, lang in sample:\n",
    "                my_s.append(char_encoding(elem, char_dict[lang])) # char encoding\n",
    "                my_s.append(spaces(elem)) # spaces\n",
    "                my_s.append(char_length(elem)) # char length\n",
    "            self.samples[sample_idx] = tuple(my_s) + sample # concats with original sample\n",
    "            \n",
    "            if (sample_idx % 10000) == 0:\n",
    "                print(\"%d of %d preprocessed ...\"  % (sample_idx, len(self.samples)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 1958868 preprocessed ...\n",
      "10000 of 1958868 preprocessed ...\n",
      "20000 of 1958868 preprocessed ...\n",
      "30000 of 1958868 preprocessed ...\n",
      "40000 of 1958868 preprocessed ...\n",
      "50000 of 1958868 preprocessed ...\n",
      "60000 of 1958868 preprocessed ...\n",
      "70000 of 1958868 preprocessed ...\n",
      "80000 of 1958868 preprocessed ...\n",
      "90000 of 1958868 preprocessed ...\n",
      "100000 of 1958868 preprocessed ...\n",
      "110000 of 1958868 preprocessed ...\n",
      "120000 of 1958868 preprocessed ...\n",
      "130000 of 1958868 preprocessed ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ea13ef8c12b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu'text_load_method = TextLoadMethod()'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2118\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2119\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2120\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2121\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m             \u001b[1;32mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/vagrant/Frostings/frostings/loader.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_load_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-dbf9dc94c2f4>\u001b[0m in \u001b[0;36m_preprocess_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;31m# samples should be tuple((train_X, \"en\") (train_t, \"fr\"))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                 \u001b[0mmy_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar_encoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchar_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# char encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m                 \u001b[0mmy_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspaces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# spaces\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[0mmy_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# char length\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-dbf9dc94c2f4>\u001b[0m in \u001b[0;36mchar_encoding\u001b[1;34m(sentence, alphadict)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# concatenating each char in the string to np.array.shape(len(sentence), len(alphadict))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mspaces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text_load_method = TextLoadMethod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('The third objective is urban and rural development, within the scope of a balanced territorial policy.',\n",
       "  'en'),\n",
       " ('', 'fr'))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_load_method(549)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "The third objective is urban and rural development, within the scope of a balanced territorial policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[123]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./data/alphabet.en', 'r') as f:\n",
    "    john = set(f.read().replace('\\r\\n', '\\n').replace('\\r', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(john)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextLoadMethod(LoadMethod):\n",
    "\n",
    "    def _load_data(self):\n",
    "        with open(\"data/train/europarl-v7.fr-en.en\", \"r\") as f:\n",
    "            self.train_X = f.read().split(\"\\n\")\n",
    "        with open(\"data/train/europarl-v7.fr-en.fr\", \"r\") as f:\n",
    "            self.train_t = f.read().split(\"\\n\")\n",
    "        self.samples = zip(self.train_X, self.train_t)\n",
    "\n",
    "    def _preprocess_data(self):\n",
    "        if self.samples == None:\n",
    "            self._load_data()\n",
    "        self.samples = sorted(self.samples, key=lambda (X, t): len(X)*10000 + len(t))\n",
    "        # remove samples not of interest\n",
    "        self.samples = remove_samples(self.samples)\n",
    "        for sample_idx, sample in enumerate(self.samples):\n",
    "            my_s = []\n",
    "            for elem in sample:# samples should be tuple(train_X, train_t)\n",
    "                # char encoding\n",
    "                my_s.append(char_encoding(elem))\n",
    "                # spaces\n",
    "                my_s.append(spaces(elem))\n",
    "                # char length\n",
    "                my_s.append(char_length(elem))\n",
    "                # word length\n",
    "                my_s.append(word_length(elem))\n",
    "            self.samples[sample_idx] = tuple(my_s) + sample # concats with original sample\n",
    "\n",
    "def get_max_length(encodings):\n",
    "\tpass\n",
    "\n",
    "class TextBatchGenerator(BatchGenerator):\n",
    "\n",
    "\tdef _make_batch_holder(self, max_length):\n",
    "\t\tself.batch = []\n",
    "\t\tpass # should make a \"holder\", e.g. self.batch.append(np.zeros((self.batch_info.batch_size, max_length, encoding_size) and .append a np.zeros for sequences_lengths, spaces etc.\n",
    "\n",
    "\tdef _make_batch(self):\n",
    "\t\tself._make_batch_holder()\n",
    "\t\tfor _ in range(len(self.samples)):\n",
    "\t\t\tpass # Should fit each sample to the holder\n",
    "\t\treturn self.batch\n",
    "\n",
    "# Chunk loader is not thought of here, but it should fit without modifying it\n",
    "\n",
    "### RUNNING THE TEXT LOADER ###\n",
    "\n",
    "text_load_method = TextLoadMethod()\n",
    "text_load_method(10000) # remember that it has a __call__ function\n",
    "\n",
    "sample_info = SampleInfo(len(text_load_method.samples)) # needs to know how many samples we have, so it can make an idx for all of them.\n",
    "sample_gen = SampleGenerator(text_load_method, sample_info) # generates one sample which consists of several elements sample = (elem, elem, elem)\n",
    "batch_info = BatchInfo(batch_size=32)\n",
    "text_batch_gen = TextBatchGenerator(sample_gen, batch_info) # Generates a batch, being a tuples\n",
    "chunk_info = ChunkInfo()\n",
    "chunk_gen = ChunkGenerator(text_batch_gen, chunk_info)\n",
    "# should be used like.\n",
    "# for train_X_char_enc, train_X_word_enc, train_X_sequence_length ... in text_batch_gen.gen_batch():"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
