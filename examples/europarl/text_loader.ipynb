{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from frostings.loader import *\n",
    "#from frostings.utils import *\n",
    "import numpy as np\n",
    "import gzip\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_gz(path, data):\n",
    "    print \"saving to %s\" %path\n",
    "    np.save(path, data)\n",
    "    gzippath = \"gzip \" + path\n",
    "    print \"running command: %s\" % gzippath\n",
    "    os.system(gzippath)\n",
    "\n",
    "def load_gz(path):\n",
    "    if path.endswith(\".gz\"):\n",
    "        print \"has the gz ...\"\n",
    "        f = gzip.open(path, 'rb')\n",
    "        print \"np loading it ..!\"\n",
    "        return np.load(f)\n",
    "    else:\n",
    "        print \"aint got no gz ..!\"\n",
    "        return np.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_samples(samples):\n",
    "    # remove input sentences that are too short or too long\n",
    "    samples = [((x, l1), (t, l2)) for (x, l1), (t, l2) in samples if len(x) > 1 and len(x) <= 400]\n",
    "\n",
    "    # remove target sentences that are too short or too long\n",
    "    samples = [((x, l1), (t, l2)) for (x, l1), (t, l2) in samples if len(t) > 1 and len(t) <= 450]\n",
    "\n",
    "    return samples\n",
    "\n",
    "class TextLoadMethod(LoadMethod):\n",
    "\n",
    "    def __init__(self):\n",
    "        self._prepare_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        print \"loading data ...\"\n",
    "        with open(\"data/train/europarl-v7.fr-en.en\", \"r\") as f:\n",
    "            self.train_X = f.read().split(\"\\n\")\n",
    "            language = [\"en\" for _ in range(len(self.train_X))] #this is bad coding ..!\n",
    "            self.train_X = zip(self.train_X, language)\n",
    "        print \"train X loaded ...\"\n",
    "        with open(\"data/train/europarl-v7.fr-en.fr\", \"r\") as f:\n",
    "            self.train_t = f.read().split(\"\\n\")\n",
    "            language = [\"fr\" for _ in range(len(self.train_t))]\n",
    "            self.train_t = zip(self.train_t, language)\n",
    "        print \"train t loaded\"\n",
    "        self.samples = zip(self.train_X, self.train_t)\n",
    "\n",
    "    def _preprocess_data(self):\n",
    "        print \"preprocessing data ...\"\n",
    "        self.samples = sorted(self.samples, key=lambda (X, t): len(X)*10000 + len(t))\n",
    "        print \"data sorted ...\"\n",
    "        # remove samples not of interest\n",
    "        self.samples = remove_samples(self.samples)\n",
    "        print \"samples of no interest removed\"\n",
    "        print len(self.samples)\n",
    "        save_gz(\"data/train.npy\", self.samples)\n",
    "\n",
    "    def _prepare_data(self):\n",
    "        print \"prepare_data started\"\n",
    "        if not os.path.exists(\"data/train.npy.gz\"):\n",
    "            self._load_data()\n",
    "            self._preprocess_data()\n",
    "        else:\n",
    "            print \"we have it!\"\n",
    "            self.samples = load_gz(\"data/train.npy.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare_data started\n",
      "we have it!\n",
      "has the gz ...\n",
      "np loading it ..!\n",
      "CPU times: user 14.3 s, sys: 1.36 s, total: 15.7 s\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text_load_method = TextLoadMethod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 'You have requested a debate on this subject in the course of the next few days, during this part-session.',\n",
       "        'en'],\n",
       "       [ 'Vous avez souhait\\xc3\\xa9 un d\\xc3\\xa9bat \\xc3\\xa0 ce sujet dans les prochains jours, au cours de cette p\\xc3\\xa9riode de session.',\n",
       "        'fr']], \n",
       "      dtype='|S450')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_load_method(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## batch\n",
    "# prepare a dictionary for mapping characters to integer tokens\n",
    "\n",
    "def get_dictionary_char(lang = 'en'):\n",
    "    with open('./data/alphabet.' + lang, 'r') as f:\n",
    "        alphabet_raw = f.read().replace('\\r\\n', '\\n').replace('\\r', '\\n') # removing microsoft formatting\n",
    "        alphabet = list(set(alphabet_raw)) # removing duplicate entries\n",
    "    return {character: idx for idx, character in enumerate(alphabet)}\n",
    "\n",
    "def char_encoding(sentence, alphadict):\n",
    "    # gets the encoding e.g. a = 180\n",
    "    encode = lambda c: alphadict[c]\n",
    "    # concatenating each char in the string to np.array.shape(len(sentence), len(alphadict))\n",
    "    encoding = [encode(c) for c in sentence]\n",
    "    return np.array(encoding)\n",
    "\n",
    "def spaces(sentence):\n",
    "    spaces = [idx-1 for idx, c in enumerate(sentence) if c == \" \"]\n",
    "    spaces.append(len(sentence)-1)\n",
    "    return np.array(spaces)\n",
    "\n",
    "def char_length(in_string):\n",
    "    return len(in_string)\n",
    "\n",
    "class TextBatchGenerator(BatchGenerator):\n",
    "\n",
    "    def _preprocess_sample(self):\n",
    "        char_dict = dict()\n",
    "        char_dict['en'] = get_dictionary_char()\n",
    "        char_dict['fr'] = get_dictionary_char('fr')\n",
    "        for sample_idx, sample in enumerate(self.samples):\n",
    "            my_s = []\n",
    "            # samples should be tuple((train_X, \"en\") (train_t, \"fr\"))\n",
    "            for elem, lang in sample:\n",
    "                my_s.append(char_encoding(elem, char_dict[lang])) # char encoding\n",
    "                my_s.append(spaces(elem)) # spaces\n",
    "                my_s.append(char_length(elem)) # char length\n",
    "            self.samples[sample_idx] = tuple(my_s)# + sample # concats with original sample\n",
    "    \n",
    "    def _make_batch_holder(self, mlen_t_X, mln_s_X, mlen_t_t, mlen_s_t):\n",
    "        self.batch = []\n",
    "        self.batch.append(np.zeros((self.batch_info.batch_size, mlen_t_X, 1)))\n",
    "        self.batch.append(np.zeros((self.batch_info.batch_size, 1)))\n",
    "        self.batch.append(np.zeros((self.batch_info.batch_size, mln_s_X, 1)))\n",
    "        self.batch.append(np.zeros((self.batch_info.batch_size, 1)))\n",
    "        self.batch.append(np.zeros((self.batch_info.batch_size, mlen_t_t, 1)))\n",
    "        self.batch.append(np.zeros((self.batch_info.batch_size, 1)))\n",
    "        self.batch.append(np.zeros((self.batch_info.batch_size, mlen_s_t, 1)))\n",
    "        self.batch.append(np.zeros((self.batch_info.batch_size, 1)))\n",
    "        \n",
    "        #pass # should make a \"holder\", e.g. self.batch.append(np.zeros((self.batch_info.batch_size, max_length, encoding_size) and .append a np.zeros for sequences_lengths, spaces etc.\n",
    "\n",
    "    def _make_batch(self):\n",
    "        self._preprocess_sample()\n",
    "        mlen_t_X = max(self.samples, key=lambda x: x[2])[2]\n",
    "        mlen_s_X = len(max(self.samples, key=lambda x: len(x[1]))[1])\n",
    "        mlen_t_t = max(self.samples, key=lambda x: x[5])[5]\n",
    "        mlen_s_t = len(max(self.samples, key=lambda x: len(x[4]))[4])\n",
    "        print mlen_t_X\n",
    "        print mlen_s_X\n",
    "        print mlen_t_t\n",
    "        print mlen_s_t\n",
    "        self._make_batch_holder(mlen_t_X, mlen_s_X, mlen_t_t, mlen_s_t)\n",
    "        for sample_idx, (t_X, s_X, l_X, t_t, s_t, l_t) in enumerate(self.samples):\n",
    "            t_X = np.array([t_X], dtype='float32').T # to shape (len,1)\n",
    "            l_s_X = len(s_X)\n",
    "            s_X = np.array([s_X], dtype='float32').T\n",
    "            t_t = np.array([t_t], dtype='float32').T\n",
    "            l_s_t = len(s_t)\n",
    "            s_t = np.array([s_t], dtype='float32').T\n",
    "            self.batch[0][sample_idx][:l_X] = t_X\n",
    "            self.batch[1][sample_idx] = l_X\n",
    "            self.batch[2][sample_idx][:l_s_X] = s_X\n",
    "            self.batch[3][sample_idx] = l_s_X\n",
    "            self.batch[4][sample_idx][:l_t] = t_t\n",
    "            self.batch[5][sample_idx] = l_t\n",
    "            self.batch[6][sample_idx][:l_s_t] = s_t\n",
    "            self.batch[7][sample_idx] = l_s_t\n",
    "\n",
    "#            assert False\n",
    "            #            self.batch[0][sample_idx] = \n",
    "            \n",
    "        self.samples = [] # resetting\n",
    "        return self.batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SampleInfo initated\n",
      "ElemGenerator initiated\n",
      "BatchInfo initiated\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 219 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sample_info = SampleInfo(len(text_load_method.samples)) # needs to know how many samples we have, so it can make an idx for all of them.\n",
    "sample_gen = SampleGenerator(text_load_method, sample_info) # generates one sample which consists of several elements sample = (elem, elem, elem)\n",
    "batch_info = BatchInfo(batch_size=32)\n",
    "text_batch_gen = TextBatchGenerator(sample_gen, batch_info) # Generates a batch, being a tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334\n",
      "57\n",
      "387\n",
      "58\n",
      "0\n",
      "109\n",
      "21\n",
      "125\n",
      "17\n",
      "1\n",
      "238\n",
      "40\n",
      "277\n",
      "42\n",
      "2\n",
      "59\n",
      "10\n",
      "82\n",
      "12\n",
      "3\n",
      "248\n",
      "47\n",
      "302\n",
      "45\n",
      "4\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-0d9c432bee77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for batch in text_batch_gen.gen_batch():\n",
    "    batch\n",
    "    print i\n",
    "    i+=1\n",
    "    if i == 5:\n",
    "        assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 248, 1)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
