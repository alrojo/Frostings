{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from frostings.loader import *\n",
    "#from frostings.utils import *\n",
    "import numpy as np\n",
    "import gzip\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_gz(path, data):\n",
    "    print \"saving to %s\" %path\n",
    "    np.save(path, data)\n",
    "    gzippath = \"gzip \" + path\n",
    "    print \"running command: %s\" % gzippath\n",
    "    os.system(gzippath)\n",
    "\n",
    "def load_gz(path):\n",
    "    if path.endswith(\".gz\"):\n",
    "        print \"has the gz ...\"\n",
    "        f = gzip.open(path, 'rb')\n",
    "        print \"np loading it ..!\"\n",
    "        return np.load(f)\n",
    "    else:\n",
    "        print \"aint got no gz ..!\"\n",
    "        return np.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_samples(samples):\n",
    "    # remove input sentences that are too short or too long\n",
    "    samples = [((x, l1), (t, l2)) for (x, l1), (t, l2) in samples if len(x) > 1 and len(x) <= 400]\n",
    "\n",
    "    # remove target sentences that are too short or too long\n",
    "    samples = [((x, l1), (t, l2)) for (x, l1), (t, l2) in samples if len(t) > 1 and len(t) <= 450]\n",
    "\n",
    "    return samples\n",
    "\n",
    "class TextLoadMethod(LoadMethod):\n",
    "\n",
    "    def __init__(self):\n",
    "        self._prepare_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        print \"loading data ...\"\n",
    "        with open(\"data/train/europarl-v7.fr-en.en\", \"r\") as f:\n",
    "            self.train_X = f.read().split(\"\\n\")\n",
    "            language = [\"en\" for _ in range(len(self.train_X))] #this is bad coding ..!\n",
    "            self.train_X = zip(self.train_X, language)\n",
    "        print \"train X loaded ...\"\n",
    "        with open(\"data/train/europarl-v7.fr-en.fr\", \"r\") as f:\n",
    "            self.train_t = f.read().split(\"\\n\")\n",
    "            language = [\"fr\" for _ in range(len(self.train_t))]\n",
    "            self.train_t = zip(self.train_t, language)\n",
    "        print \"train t loaded\"\n",
    "        self.samples = zip(self.train_X, self.train_t)\n",
    "\n",
    "    def _preprocess_data(self):\n",
    "        print \"preprocessing data ...\"\n",
    "        self.samples = sorted(self.samples, key=lambda (X, t): len(X)*10000 + len(t))\n",
    "        print \"data sorted ...\"\n",
    "        # remove samples not of interest\n",
    "        self.samples = remove_samples(self.samples)\n",
    "        print \"samples of no interest removed\"\n",
    "        print len(self.samples)\n",
    "        save_gz(\"data/train.npy\", self.samples)\n",
    "\n",
    "    def _prepare_data(self):\n",
    "        print \"prepare_data started\"\n",
    "        if not os.path.exists(\"data/train.npy.gz\"):\n",
    "            self._load_data()\n",
    "            self._preprocess_data()\n",
    "        else:\n",
    "            print \"we have it!\"\n",
    "            self.samples = load_gz(\"data/train.npy.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare_data started\n",
      "we have it!\n",
      "has the gz ...\n",
      "np loading it ..!\n",
      "CPU times: user 13.3 s, sys: 1.38 s, total: 14.7 s\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text_load_method = TextLoadMethod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 'You have requested a debate on this subject in the course of the next few days, during this part-session.',\n",
       "        'en'],\n",
       "       [ 'Vous avez souhait\\xc3\\xa9 un d\\xc3\\xa9bat \\xc3\\xa0 ce sujet dans les prochains jours, au cours de cette p\\xc3\\xa9riode de session.',\n",
       "        'fr']], \n",
       "      dtype='|S450')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_load_method(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## batch\n",
    "# prepare a dictionary for mapping characters to integer tokens\n",
    "\n",
    "def get_dictionary_char(lang = 'en'):\n",
    "    with open('./data/alphabet.' + lang, 'r') as f:\n",
    "        alphabet_raw = f.read().replace('\\r\\n', '\\n').replace('\\r', '\\n') # removing microsoft formatting\n",
    "        alphabet = list(set(alphabet_raw)) # removing duplicate entries\n",
    "    return {character: idx for idx, character in enumerate(alphabet)}\n",
    "\n",
    "def char_encoding(sentence, alphadict):\n",
    "    # gets the encoding e.g. a = 180\n",
    "    encode = lambda c: alphadict[c]\n",
    "    # concatenating each char in the string to np.array.shape(len(sentence), len(alphadict))\n",
    "    encoding = [encode(c) for c in sentence]\n",
    "    return np.array(encoding)\n",
    "\n",
    "def spaces(sentence):\n",
    "    spaces = [idx-1 for idx, c in enumerate(sentence) if c == \" \"]\n",
    "    spaces.append(len(sentence)-1)\n",
    "    return np.array(spaces)\n",
    "\n",
    "def char_length(in_string):\n",
    "    return len(in_string)\n",
    "\n",
    "class TextBatchGenerator(BatchGenerator):\n",
    "\n",
    "    def _preprocess_sample(self):\n",
    "        char_dict = dict()\n",
    "        char_dict['en'] = get_dictionary_char()\n",
    "        char_dict['fr'] = get_dictionary_char('fr')\n",
    "        for sample_idx, sample in enumerate(self.samples):\n",
    "            my_s = []\n",
    "            # samples should be tuple((train_X, \"en\") (train_t, \"fr\"))\n",
    "            for elem, lang in sample:\n",
    "                my_s.append(char_encoding(elem, char_dict[lang])) # char encoding\n",
    "                my_s.append(spaces(elem)) # spaces\n",
    "                my_s.append(char_length(elem)) # char length\n",
    "            self.samples[sample_idx] = tuple(my_s)# + sample # concats with original sample\n",
    "    \n",
    "    def _make_batch_holder(self):\n",
    "        self.batch = []\n",
    "        #pass # should make a \"holder\", e.g. self.batch.append(np.zeros((self.batch_info.batch_size, max_length, encoding_size) and .append a np.zeros for sequences_lengths, spaces etc.\n",
    "\n",
    "    def _make_batch(self):\n",
    "        self._preprocess_sample()\n",
    "        self._make_batch_holder()\n",
    "        for idx in range(len(self.samples)):\n",
    "            self.batch.append(self.samples[idx])\n",
    "        self.samples = []\n",
    "        return self.batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SampleInfo initated\n",
      "ElemGenerator initiated\n",
      "BatchInfo initiated\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 280 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sample_info = SampleInfo(len(text_load_method.samples)) # needs to know how many samples we have, so it can make an idx for all of them.\n",
    "sample_gen = SampleGenerator(text_load_method, sample_info) # generates one sample which consists of several elements sample = (elem, elem, elem)\n",
    "batch_info = BatchInfo(batch_size=32)\n",
    "text_batch_gen = TextBatchGenerator(sample_gen, batch_info) # Generates a batch, being a tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-117b4636d650>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext_batch_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for batch in text_batch_gen.gen_batch():\n",
    "    batch\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO IN FUTURE\n",
    "\n",
    "class TextLoadMethod(LoadMethod):\n",
    "\n",
    "    def _load_data(self):\n",
    "        with open(\"data/train/europarl-v7.fr-en.en\", \"r\") as f:\n",
    "            self.train_X = f.read().split(\"\\n\")\n",
    "        with open(\"data/train/europarl-v7.fr-en.fr\", \"r\") as f:\n",
    "            self.train_t = f.read().split(\"\\n\")\n",
    "        self.samples = zip(self.train_X, self.train_t)\n",
    "\n",
    "    def _preprocess_data(self):\n",
    "        if self.samples == None:\n",
    "            self._load_data()\n",
    "        self.samples = sorted(self.samples, key=lambda (X, t): len(X)*10000 + len(t))\n",
    "        # remove samples not of interest\n",
    "        self.samples = remove_samples(self.samples)\n",
    "        for sample_idx, sample in enumerate(self.samples):\n",
    "            my_s = []\n",
    "            for elem in sample:# samples should be tuple(train_X, train_t)\n",
    "                # char encoding\n",
    "                my_s.append(char_encoding(elem))\n",
    "                # spaces\n",
    "                my_s.append(spaces(elem))\n",
    "                # char length\n",
    "                my_s.append(char_length(elem))\n",
    "                # word length\n",
    "                my_s.append(word_length(elem))\n",
    "            self.samples[sample_idx] = tuple(my_s) + sample # concats with original sample\n",
    "\n",
    "def get_max_length(encodings):\n",
    "\tpass\n",
    "\n",
    "class TextBatchGenerator(BatchGenerator):\n",
    "\n",
    "\tdef _make_batch_holder(self, max_length):\n",
    "\t\tself.batch = []\n",
    "\t\tpass # should make a \"holder\", e.g. self.batch.append(np.zeros((self.batch_info.batch_size, max_length, encoding_size) and .append a np.zeros for sequences_lengths, spaces etc.\n",
    "\n",
    "\tdef _make_batch(self):\n",
    "\t\tself._make_batch_holder()\n",
    "\t\tfor _ in range(len(self.samples)):\n",
    "\t\t\tpass # Should fit each sample to the holder\n",
    "\t\treturn self.batch\n",
    "\n",
    "# Chunk loader is not thought of here, but it should fit without modifying it\n",
    "\n",
    "### RUNNING THE TEXT LOADER ###\n",
    "\n",
    "text_load_method = TextLoadMethod()\n",
    "text_load_method(10000) # remember that it has a __call__ function\n",
    "\n",
    "sample_info = SampleInfo(len(text_load_method.samples)) # needs to know how many samples we have, so it can make an idx for all of them.\n",
    "sample_gen = SampleGenerator(text_load_method, sample_info) # generates one sample which consists of several elements sample = (elem, elem, elem)\n",
    "batch_info = BatchInfo(batch_size=32)\n",
    "text_batch_gen = TextBatchGenerator(sample_gen, batch_info) # Generates a batch, being a tuples\n",
    "chunk_info = ChunkInfo()\n",
    "chunk_gen = ChunkGenerator(text_batch_gen, chunk_info)\n",
    "# should be used like.\n",
    "# for train_X_char_enc, train_X_word_enc, train_X_sequence_length ... in text_batch_gen.gen_batch():"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
